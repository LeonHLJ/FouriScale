# T_references for training size (512)
Tref = {
    "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor": {4096},
    "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor": {77},
    "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor": {4096},
    "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor": {77},
    "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor": {1024},
    "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor": {77},
    "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor": {1024},
    "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor": {77},
    "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor": {256},
    "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor": {77},
    "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor": {256},
    "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor": {77},
    "mid_block.attentions.0.transformer_blocks.0.attn1.processor": {64},
    "mid_block.attentions.0.transformer_blocks.0.attn2.processor": {77},
    "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor": {256},
    "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor": {77},
    "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor": {256},
    "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor": {77},
    "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor": {256},
    "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor": {77},
    "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor": {1024},
    "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor": {77},
    "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor": {1024},
    "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor": {77},
    "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor": {1024},
    "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor": {77},
    "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor": {4096},
    "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor": {77},
    "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor": {4096},
    "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor": {77},
    "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor": {4096},
    "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor": {77},
}

list_layers = [
    "down_blocks.1.attentions.0.transformer_blocks.0.attn1",
    "down_blocks.1.attentions.0.transformer_blocks.0.attn2",
    "down_blocks.1.attentions.0.transformer_blocks.1.attn1",
    "down_blocks.1.attentions.0.transformer_blocks.1.attn2",
    "down_blocks.1.attentions.1.transformer_blocks.0.attn1",
    "down_blocks.1.attentions.1.transformer_blocks.0.attn2",
    "down_blocks.1.attentions.1.transformer_blocks.1.attn1",
    "down_blocks.1.attentions.1.transformer_blocks.1.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.0.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.0.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.1.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.1.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.2.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.2.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.3.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.3.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.4.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.4.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.5.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.5.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.6.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.6.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.7.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.7.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.8.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.8.attn2",
    "down_blocks.2.attentions.0.transformer_blocks.9.attn1",
    "down_blocks.2.attentions.0.transformer_blocks.9.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.0.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.0.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.1.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.1.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.2.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.2.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.3.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.3.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.4.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.4.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.5.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.5.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.6.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.6.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.7.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.7.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.8.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.8.attn2",
    "down_blocks.2.attentions.1.transformer_blocks.9.attn1",
    "down_blocks.2.attentions.1.transformer_blocks.9.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.0.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.0.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.1.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.1.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.2.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.2.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.3.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.3.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.4.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.4.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.5.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.5.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.6.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.6.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.7.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.7.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.8.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.8.attn2",
    "up_blocks.0.attentions.0.transformer_blocks.9.attn1",
    "up_blocks.0.attentions.0.transformer_blocks.9.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.0.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.0.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.1.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.1.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.2.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.2.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.3.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.3.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.4.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.4.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.5.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.5.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.6.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.6.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.7.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.7.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.8.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.8.attn2",
    "up_blocks.0.attentions.1.transformer_blocks.9.attn1",
    "up_blocks.0.attentions.1.transformer_blocks.9.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.0.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.0.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.1.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.1.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.2.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.2.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.3.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.3.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.4.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.4.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.5.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.5.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.6.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.6.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.7.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.7.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.8.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.8.attn2",
    "up_blocks.0.attentions.2.transformer_blocks.9.attn1",
    "up_blocks.0.attentions.2.transformer_blocks.9.attn2",
    "up_blocks.1.attentions.0.transformer_blocks.0.attn1",
    "up_blocks.1.attentions.0.transformer_blocks.0.attn2",
    "up_blocks.1.attentions.0.transformer_blocks.1.attn1",
    "up_blocks.1.attentions.0.transformer_blocks.1.attn2",
    "up_blocks.1.attentions.1.transformer_blocks.0.attn1",
    "up_blocks.1.attentions.1.transformer_blocks.0.attn2",
    "up_blocks.1.attentions.1.transformer_blocks.1.attn1",
    "up_blocks.1.attentions.1.transformer_blocks.1.attn2",
    "up_blocks.1.attentions.2.transformer_blocks.0.attn1",
    "up_blocks.1.attentions.2.transformer_blocks.0.attn2",
    "up_blocks.1.attentions.2.transformer_blocks.1.attn1",
    "up_blocks.1.attentions.2.transformer_blocks.1.attn2",
    "mid_block.attentions.0.transformer_blocks.0.attn1",
    "mid_block.attentions.0.transformer_blocks.0.attn2",
    "mid_block.attentions.0.transformer_blocks.1.attn1",
    "mid_block.attentions.0.transformer_blocks.1.attn2",
    "mid_block.attentions.0.transformer_blocks.2.attn1",
    "mid_block.attentions.0.transformer_blocks.2.attn2",
    "mid_block.attentions.0.transformer_blocks.3.attn1",
    "mid_block.attentions.0.transformer_blocks.3.attn2",
    "mid_block.attentions.0.transformer_blocks.4.attn1",
    "mid_block.attentions.0.transformer_blocks.4.attn2",
    "mid_block.attentions.0.transformer_blocks.5.attn1",
    "mid_block.attentions.0.transformer_blocks.5.attn2",
    "mid_block.attentions.0.transformer_blocks.6.attn1",
    "mid_block.attentions.0.transformer_blocks.6.attn2",
    "mid_block.attentions.0.transformer_blocks.7.attn1",
    "mid_block.attentions.0.transformer_blocks.7.attn2",
    "mid_block.attentions.0.transformer_blocks.8.attn1",
    "mid_block.attentions.0.transformer_blocks.8.attn2",
    "mid_block.attentions.0.transformer_blocks.9.attn1",
    "mid_block.attentions.0.transformer_blocks.9.attn2",

]
list_layers = list(map(lambda x: x + ".processor", list_layers))
